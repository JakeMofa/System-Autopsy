## Scenario 1 , Simulation with multiple Scenarios
https://github.com/user-attachments/assets/559727d3-f8bc-4898-95cb-35730e647fbd

## Scenario 2, LLM Bounded Gen AI, Insight Analysis, no hallucination off data from system
https://github.com/user-attachments/assets/979afcd9-eac1-40b0-ab1f-cddfe54bac05






## System Autopsy 

System Autopsy is a failure simulation and explanation system that models how distributed systems degrade under stress and uses a bounded AI-assisted explanation layer to help engineers understand why failures occur and how they propagate.

The system is intentionally synthetic, deterministic, and explanation-focused.
It is not a monitoring tool, alerting system, or automated remediation platform.

## What is System Autopsy

System Autopsy uses AI strictly as an interpretation layer, not as a decision-making or control system.

All system behavior — including failure detection, degraded mode transitions, and dependency propagation — is produced by a deterministic simulation engine governed by explicit rules before any LLM is invoked.

The AI layer receives only structured, synthetic operational summaries, such as:
Service latency
Error rates
Dependency states
Failure propagation paths
Metric trends over time

Its sole responsibility is to translate these known signals into human-readable explanations that resemble real incident postmortems.

The LLM:
Does not evaluate thresholds
Does not trigger actions
Does not modify system state
Does not introduce new causes or metrics

To reduce hallucination risk:
Inputs are schema-constrained
Failure vocabulary is predefined
Outputs are validated against known services and metrics
Invalid outputs fall back to deterministic explanations
This design treats AI as an interpreter of system behavior, not an authority — prioritizing correctness, explainability, and engineering safety.



## Why i built this

Most incident tooling focuses on detection, not understanding.
System Autopsy was built to model how distributed systems actually degrade under stress — latency amplification, retry cascades, downstream saturation  and to explain that behavior in a way that mirrors real incident postmortems.

It is intentionally:
Synthetic (no production data)
Deterministic (repeatable logic)
Explanation-centric (understanding over automation)

## High Level Architecture

[ System Model ]
       ↓
[ Telemetry Simulator ]
       ↓
[ Failure Injection Engine ]
       ↓
[ Dependency / Propagation Engine ]
       ↓
[ Explanation Generator (LLM) ]
       ↓
[ Human-readable Autopsy Report ]


## AI Scope & Boundaries

System Autopsy deliberately constrains AI usage to explanation only.

The AI layer:
Does not detect failures
Does not determine system state
Does not trigger mitigations
Does not access external knowledge or the internet
It operates solely on fully structured system summaries generated by deterministic logic.

The system remains fully functional without AI enabled.
AI output is validated and never influences system state or decisions.


## Future Work

System Autopsy is intentionally scoped as a failure simulation and explanation system rather than a production monitoring or automation platform. Future work focuses on **deepening understanding, extensibility, and safe AI integration** without expanding system control or increasing operational risk.
Planned and potential extensions include:

- **Expanded Failure Scenarios**  
  Support for additional degradation patterns such as cache stampedes, configuration rollouts, partial network partitions, retry storms, and resource contention.
- **Richer Failure Timelines**  
  More detailed event sequencing and causal timelines to visualize how failures propagate across services over time.
- **Configurable Simulation Parameters**  
  Adjustable traffic volume, retry policies, dependency latency, and saturation thresholds to explore system behavior under different operating conditions.
- **Deterministic Replay & Comparison**  
  Seeded simulations enabling reproducible runs, side-by-side baseline vs failure comparisons, and repeatable postmortem analysis.
- **API-First Integration Layer**  
  A future API that allows teams to connect System Autopsy to their own systems or observability exports, enabling consistent failure modeling and explanation without embedding AI throughout production infrastructure.
- **Cross-System Pattern Accumulation**  
  As System Autopsy is applied across multiple systems and simulations, the explanation layer can accumulate knowledge of recurring failure patterns, common propagation paths, and typical degradation signatures. This enables more informed explanations while remaining grounded in explicit rules and known signals.
- **AI-Assisted Troubleshooting & Debugging**  
  Over time, the bounded AI layer may provide increasingly refined troubleshooting insights and engineering remarks based on previously observed failure behaviors. These insights remain explanatory and advisory only, never autonomous or state-altering.
- **Bounded AI for Observability & Ops Assistance**  
  Exploration of System Autopsy as a shared, bounded AI ops assistant that helps interpret system behavior and observability data across environments, reducing hallucination risk by centralizing AI usage behind strict schemas, validation, and deterministic fallback.
- **Non-Authoritative Mitigation Guidance**  
  Optional mitigation suggestions derived from known failure patterns, presented as clearly labeled guidance rather than automated actions or enforced decisions.
All future extensions preserve the system’s core principles: **synthetic or explicitly modeled data, deterministic behavior, explicit rules, and AI used strictly for interpretation rather than control or decision-making**.


## Features

- **Failure Simulation**
Inject controlled latency, error, and dependency degradation scenarios.
- **Deterministic Failure Propagation**
Explicit rules define how failures cascade across service dependencies.
- **AI-Assisted Explanations**
Human-readable narratives describing root causes, blast radius, and degradation paths.
- **System Topology Visualization**
Service dependency graph with health and state indicators.
- **Operational Metrics Dashboard**
Synthetic time-series charts for latency, error rates, request volume, and queue depth.

## Tech Stack
 - **Frontend**
- **React 18** with TypeScript
- **Vite** for fast development and building
- **Tailwind CSS 4** for styling
- **Recharts** for data visualization
- **Lucide React** for icons

- **Backend**

- **FastAPI** (Python)
- **Deterministic** simulation engine
- **Dependency-aware** failure propagation
- **Structured explanation** payloads

**AI**

- **Ollama** (local inference)
- **LLaMA / Mistral** models
- **Schema-bounded** prompts
- **Output validation** with deterministic fallback



## Getting Started

### Prerequisites

- Homebrew / pip
- Node.js 18+
- Python 3.10+
- Ollama

```bash 
Install Ollama (Local LLM Runtime)
brew install ollama
ollama serve 
```  

Pull a model once:
- ollama pull mistral
# or
- ollama pull llama3


Ollama runs locally at:
http://127.0.0.1:11434

- Backend Setup
- cd backend
- python3 -m venv venv
- source venv/bin/activate
- pip install -r requirements.txt
- uvicorn app.main:app --reload


Backend runs at:

http://127.0.0.1:8000

Frontend Setup
cd frontend
```  bash
npm install
npm run dev
```  

Frontend runs at:

http://localhost:3000

Usage Flow:
- Select a failure scenario
- Inject the failure
- Run the deterministic simulation
- Review system topology and metrics
- Click Explain Failure
- Receive an AI-assisted explanation grounded in visible data
AI is invoked only on demand.

## Development Notes

- All telemetry is synthetic
- No authentication or user management
- No production data
- Designed to resemble internal engineering tooling
- Safe for demos, learning, and architectural discussion

## License

Private repository - all rights reserved
